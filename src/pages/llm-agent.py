import streamlit as st

# TODO:ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’ã‚‚ã¨ã«è³‡æ ¼ã®æƒ…å ±ã‚’æ¤œç´¢ã—ã¦ã„ã‚‹ãŸã‚ã€ãƒ¡ã‚¤ãƒ³ç”»é¢ã«ä¸€åº¦è¡Œã‹ãªã„ã¨æ­£ã—ãæƒ…å ±ã®ç´ã¥ã‘ãŒã§ããªã„
st.set_page_config(
    page_title="AIã‚³ãƒ¼ãƒãƒ³ã‚°",
    page_icon="ğŸ§Š",
    layout="wide",
    initial_sidebar_state="expanded",

)
import json
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver
from services.db_operation import init_supabase
supabase =init_supabase()
try:
    exam_list = json.loads(supabase.table("Learning materials").select("user_id,exam_id,exam_date,learning_materials").eq("user_id",str(st.session_state.user_id)).execute().model_dump_json())
    exam_id = exam_list["data"][0]["exam_id"]
    exam =  json.loads(supabase.table("qualification").select("id,exam_name").eq("id",exam_id).execute().model_dump_json())
    st.session_state["exam_name_agent"] = exam["data"][0]["exam_name"]
    st.session_state["exam_date_agent"] = exam_list["data"][0]["exam_date"]
    st.session_state["learning_materials_agent"] = exam_list["data"][0]["learning_materials"]
    st.session_state["learning_time_agent"] = exam_list["data"][0]["learning_time"]
except:
    st.session_state["exam_name_agent"] = "æƒ…å ±ç™»éŒ²ãªã—"
    st.session_state["exam_date_agent"] = "æƒ…å ±ç™»éŒ²ãªã—"
    st.session_state["learning_materials_agent"] = "æƒ…å ±ç™»éŒ²ãªã—"
    st.write("ç™»éŒ²æƒ…å ±ãªã—")


model = ChatOpenAI(model="gpt-5-nano", temperature=0)

# StreamlitãŒå†å®Ÿè¡Œã•ã‚Œã¦ã‚‚è¨˜æ†¶ãŒæ¶ˆãˆãªã„ã‚ˆã†ã« session_state ã«ä¿å­˜ã—ã¾ã™
if "memory_support" not in st.session_state:
    st.session_state.memory_support = MemorySaver()

memory = st.session_state.memory_support
prompt = f"""
    ã‚ãªãŸã¯è³‡æ ¼è©¦é¨“ã‚µãƒãƒ¼ãƒˆã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ã¯è³‡æ ¼è©¦é¨“ã®å‹‰å¼·ã®ä»•æ–¹ã‚„ä½•ã‚’ã™ã¹ãã‹ã‚’è¿·ã£ã¦ã„ã¾ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ã®ãƒ‹ãƒ¼ã‚ºã‚„çŠ¶æ³ã‚’èãå‡ºã—ã€ã‚¢ã‚µãƒ¼ãƒ†ã‚£ãƒ–ã«ãƒ¦ãƒ¼ã‚¶ã®æ„å›³ã«æ²¿ã£ãŸå›ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚

    ãƒ¦ãƒ¼ã‚¶ãŒå—ã‘ã‚‹è³‡æ ¼è©¦é¨“ã®æƒ…å ±ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

    è³‡æ ¼å: {st.session_state.exam_name_agent}
    è©¦é¨“æ—¥: {st.session_state.exam_date_agent}
    å­¦ç¿’æ•™æ: {st.session_state.learning_materials_agent}

    ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ã«æœ€é©ãªå­¦ç¿’æ–¹æ³•ã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
    """


agent_executor = create_agent(model,system_prompt=prompt ,checkpointer=memory)

# ã‚¹ãƒ¬ãƒƒãƒ‰IDã®è¨­å®š
config = {"configurable": {"thread_id": "streamlit_user_id"}}

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
snapshot = agent_executor.get_state(config)
st.chat_message("assistant").markdown("ã“ã‚“ã«ã¡ã¯ï¼è³‡æ ¼è©¦é¨“ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ãŠæ‰‹ä¼ã„ã—ã¾ã™ã€‚")
if snapshot.values:
    for msg in snapshot.values["messages"]:
        # LangGraphã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã‚’Streamlitã«åˆã‚ã›ã¦è¡¨ç¤º
        with st.chat_message(msg.type):
            st.write(msg.content)

# ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã¨LLMå®Ÿè¡Œ
if prompt := st.chat_input("ã§ã‚‚èã„ã¦ãã ã•ã„"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å³æ™‚è¡¨ç¤º
    with st.chat_message("user"):
        st.write(prompt)
    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œã¨å¿œç­”è¡¨ç¤º
    with st.chat_message("assistant"):
        # streamã‚’ä½¿ã†ã¨ã€æ–‡å­—ãŒå°‘ã—ãšã¤å‡ºã‚‹ã‚ˆã†ãªæ¼”å‡ºã‚‚å¯èƒ½ã§ã™
        response_container = st.empty()
        full_response = ""
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ (å…¥åŠ›ã¯ messages ã‚­ãƒ¼ã§æ¸¡ã™)
        # stream_mode="values" ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ›´æ–°ã‚’å—ã‘å–ã‚‹
        events = agent_executor.stream(
            {"messages": [("user", prompt)]},
            config,
            stream_mode="values"
        )

        for event in events:
            # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒAIã‹ã‚‰ã®ã‚‚ã®ãªã‚‰è¡¨ç¤ºã‚’æ›´æ–°
            if "messages" in event:
                last_msg = event["messages"][-1]
                if last_msg.type == "ai":
                    full_response = last_msg.content
                    response_container.write(full_response)